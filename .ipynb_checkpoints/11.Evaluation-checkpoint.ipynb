{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>RunsScored</th>\n",
       "      <th>RunsAllowed</th>\n",
       "      <th>Wins</th>\n",
       "      <th>OnBasePercentage</th>\n",
       "      <th>SluggingPercentage</th>\n",
       "      <th>BattingAverage</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>RankSeason</th>\n",
       "      <th>RankPlayoffs</th>\n",
       "      <th>GamesPlayed</th>\n",
       "      <th>OpponentOnBasePercentage</th>\n",
       "      <th>OpponentSluggingPercentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>SFG</td>\n",
       "      <td>NL</td>\n",
       "      <td>1999</td>\n",
       "      <td>872</td>\n",
       "      <td>831</td>\n",
       "      <td>86</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>STL</td>\n",
       "      <td>NL</td>\n",
       "      <td>1999</td>\n",
       "      <td>809</td>\n",
       "      <td>838</td>\n",
       "      <td>75</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>TBD</td>\n",
       "      <td>AL</td>\n",
       "      <td>1999</td>\n",
       "      <td>772</td>\n",
       "      <td>913</td>\n",
       "      <td>69</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>TEX</td>\n",
       "      <td>AL</td>\n",
       "      <td>1999</td>\n",
       "      <td>945</td>\n",
       "      <td>859</td>\n",
       "      <td>95</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.293</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>TOR</td>\n",
       "      <td>AL</td>\n",
       "      <td>1999</td>\n",
       "      <td>883</td>\n",
       "      <td>862</td>\n",
       "      <td>84</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Team League  Year  RunsScored  RunsAllowed  Wins  OnBasePercentage  \\\n",
       "415  SFG     NL  1999         872          831    86             0.356   \n",
       "416  STL     NL  1999         809          838    75             0.338   \n",
       "417  TBD     AL  1999         772          913    69             0.343   \n",
       "418  TEX     AL  1999         945          859    95             0.361   \n",
       "419  TOR     AL  1999         883          862    84             0.352   \n",
       "\n",
       "     SluggingPercentage  BattingAverage  Playoffs  RankSeason  RankPlayoffs  \\\n",
       "415               0.434           0.271         0         NaN           NaN   \n",
       "416               0.426           0.262         0         NaN           NaN   \n",
       "417               0.411           0.274         0         NaN           NaN   \n",
       "418               0.479           0.293         1         5.0           4.0   \n",
       "419               0.457           0.280         0         NaN           NaN   \n",
       "\n",
       "     GamesPlayed  OpponentOnBasePercentage  OpponentSluggingPercentage  \n",
       "415          162                     0.345                       0.423  \n",
       "416          161                     0.355                       0.427  \n",
       "417          162                     0.371                       0.448  \n",
       "418          162                     0.346                       0.459  \n",
       "419          162                     0.353                       0.456  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from file\n",
    "import pandas as pd\n",
    "df=pd.read_csv('baseball.csv').dropna(subset=['OpponentOnBasePercentage', 'OpponentSluggingPercentage'])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predict whether a team will make to playoffs based on its and oppoments' statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df[['OnBasePercentage','SluggingPercentage','BattingAverage','OpponentOnBasePercentage', 'OpponentSluggingPercentage']]\n",
    "y=df['Playoffs']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7238095238095238, 0.0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
    "y_dummy_predictions = dummy_majority.predict(X_test)\n",
    "\n",
    "dummy_majority.score(X_test, y_test), recall_score(y_test, y_dummy_predictions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Train a SVC classifer using the default parameters. What is the accuracy, recall, and precision of this classifier?\n",
    "- Precision = tp / (tp + fp)\n",
    "- Recall = tp / (tp + fn)\n",
    "<img src='https://miro.medium.com/max/700/1*LQ1YMKBlbDhH9K6Ujz8QTw.jpeg' width=30%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7238095238095238, 0.0, 0.0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf=SVC().fit(X_train,y_train)\n",
    "y_predicted=clf.predict(X_test)\n",
    "\n",
    "clf.score(X_test,y_test), recall_score(y_test,y_predicted), precision_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using the SVC classifier with parameters `{'C', 'gamma'}`, what is the confusion matrix when using a threshold on the decision function. Use X_test and y_test.\n",
    "\n",
    "Return a confusion matrix, a 2x2 numpy array with 4 integers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.8761904761904762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68,  8],\n",
       "       [ 5, 24]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "clf = SVC(C=1e9, gamma=1e-07)\n",
    "clf.fit(X_train, y_train)\n",
    "y_scores = clf.decision_function(X_test) >12 #Threshold\n",
    "cm = confusion_matrix(y_test, y_scores)\n",
    "print('Accuracy is:',(cm[0,0]+cm[1,1])/np.sum(cm))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a logisitic regression classifier with default parameters using X_train and y_train.<br>\n",
    "For the logisitic regression classifier, create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is playoffs).<br>\n",
    "Looking at the precision recall curve, what is the recall when the precision is `0.75`?<br>\n",
    "Looking at the roc curve, what is the true positive rate when the false positive rate is `0.16`?<br>\n",
    "Return (recall, true positive rate)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf=LogisticRegression().fit(X_train,y_train)\n",
    "y_predicts=clf.predict(X_test)\n",
    "y_scores=clf.decision_function(X_test)\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "closest_zero = np.argmin(np.abs(thresholds))\n",
    "closest_zero_p = precision[closest_zero]\n",
    "closest_zero_r = recall[closest_zero]\n",
    "plt.figure()\n",
    "plt.xlim([0.0, 1.01])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.plot(precision, recall, label='Precision-Recall Curve')\n",
    "plt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\n",
    "plt.xlabel('Precision', fontsize=16)\n",
    "plt.ylabel('Recall', fontsize=16)\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_scores)\n",
    "roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "plt.figure()\n",
    "plt.xlim([-0.01, 1.00])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.plot(fpr_lr, tpr_lr, lw=3, label='LogRegr ROC curve (area = {:0.2f})'.format(roc_auc_lr))\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve (1-of-10 digits classifier)', fontsize=16)\n",
    "plt.legend(loc='lower right', fontsize=13)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.\n",
    "\n",
    "`'penalty': ['l1', 'l2']`\n",
    "\n",
    "`'C':[0.01, 0.1, 1, 10, 100]`\n",
    "\n",
    "Create an array of the mean test scores of each parameter combination. i.e.\n",
    "\n",
    "*This function should return a 5 by 2 numpy array with 10 floats.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "grid_values = {'C':[0.01, 0.1, 1, 10, 100],'penalty': ['l1', 'l2']}\n",
    "clf=LogisticRegression()\n",
    "grid_clf = GridSearchCV(clf, param_grid = grid_values, scoring = 'recall',cv=3)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "ls=grid_clf.grid_scores_\n",
    "arr=list()\n",
    "for i in range(10):\n",
    "    arr.append(ls[i][1])\n",
    "ar=np.array(arr)\n",
    "scores=ar.reshape(5,2)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results from the grid search\n",
    "%matplotlib notebook\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "sns.heatmap(scores.reshape(5,2), xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10, 100])\n",
    "plt.yticks(rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predict the probability that a record will be in playoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=baseball[['Wins', 'RunsScored', 'OnBasePercentage', 'SluggingPercentage', 'RunsAllowed']]\n",
    "y=baseball['Playoffs']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "clf = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "playoffProbability_predicts=clf.predict_proba(X_test)[:,1] \n",
    "playoffProbability_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
